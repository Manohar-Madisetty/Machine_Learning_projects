{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  61.4/62.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 62.6/62.6 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 143.4/162.5 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.5/162.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 92.2/99.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.9/99.9 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.6 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 30.7/61.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.6/61.6 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  102.4/104.6 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 104.6/104.6 kB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 idna-3.6 requests-2.31.0 urllib3-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "     ---------------------------------------- 0.0/143.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 143.0/143.0 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep 2020Dec 2020Mar 2021Jun 2021Sep 2021Dec 2021Mar 2022Jun 2022Sep 2022Dec 2022Mar 2023Jun 2023Sep 2023Sales+19,26421,85926,93428,90232,50338,07146,89538,08641,77839,13446,96242,21344,584Expenses+14,85015,91818,49418,62822,08628,93937,74233,79440,08234,64339,03135,20136,722Operating Profit4,4145,9418,44010,27410,4179,1329,1534,2921,6964,4917,9317,0127,862OPM %23%27%31%36%32%24%20%11%4%11%17%17%18%Other Income+199147905211,549176-508189779188465331826Interest9599771,0059939361,2831,7561,4221,5231,8192,1381,9632,084Depreciation1,1491,2301,2531,1831,2391,7641,8151,7781,8051,8822,0091,9002,019Profit before tax2,5053,8816,2728,6199,7916,2615,0741,281-8539784,2493,4804,585Tax %36%31%33%32%27%28%34%34%-7%52%12%30%40%Net Profit+1,5952,6694,1915,9007,1794,5163,343839-9154743,7412,4282,773EPS in Rs6.5911.0917.3724.4229.6618.0213.383.47-3.512.0315.169.6711.29Raw PDF\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify the URL\n",
    "url = \"https://www.screener.in/company/JSWSTEEL/consolidated/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the element with class \"responsive-holder fill-card-width\"\n",
    "    data_element = soup.find('div', class_='responsive-holder fill-card-width')\n",
    "\n",
    "    # Extract the text content of the element\n",
    "    if data_element:\n",
    "        scraped_data = data_element.get_text(strip=True)\n",
    "        print(scraped_data)\n",
    "    else:\n",
    "        print(\"Data element not found on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ManoharMadisetty\\ML_Learning\\Quarterly_Results.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ManoharMadisetty/ML_Learning/Quarterly_Results.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m resp\u001b[39m=\u001b[39mrequests\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ManoharMadisetty/ML_Learning/Quarterly_Results.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(resp)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ManoharMadisetty/ML_Learning/Quarterly_Results.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m soup\u001b[39m=\u001b[39mBeautifulSoup(resp\u001b[39m.\u001b[39;49mtext,\u001b[39m\"\u001b[39;49m\u001b[39mlxml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ManoharMadisetty/ML_Learning/Quarterly_Results.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m table\u001b[39m=\u001b[39msoup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m,class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata-table responsive-text-nowrap\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ManoharMadisetty/ML_Learning/Quarterly_Results.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(table)\n",
      "File \u001b[1;32mc:\\Users\\ManoharMadisetty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[39m=\u001b[39m builder_registry\u001b[39m.\u001b[39mlookup(\u001b[39m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m builder_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a tree builder with the features you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Do you need to install a parser library?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "url=\"https://www.screener.in/company/JSWSTEEL/consolidated/\"\n",
    "resp=requests.get(url)\n",
    "print(resp)\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(resp.text,\"lxml\")\n",
    "table=soup.find(\"div\",class_=\"data-table responsive-text-nowrap\")\n",
    "print(table)\n",
    "headers=table.find_all(\"tr\")\n",
    "# print(headers)\n",
    " \n",
    "titles=[]\n",
    " \n",
    "for i in headers:\n",
    "  title=i.text\n",
    "  titles.append(title)\n",
    " \n",
    "print(titles)\n",
    " \n",
    "df=pd.DataFrame(columns=titles)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 1.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 973.5 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.6/3.8 MB 939.0 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.6/3.8 MB 901.1 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.6/3.8 MB 853.3 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.7/3.8 MB 932.2 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.7/3.8 MB 901.1 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.8/3.8 MB 982.7 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.5/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.8/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                Sales +\n",
      "\n",
      "\n",
      "4,642\n",
      "5,550\n",
      "6,197\n",
      "6,939\n",
      "7,507\n",
      "9,047\n",
      "9,267\n",
      "11,134\n",
      "13,421\n",
      "15,771\n",
      "20,299\n",
      "23,892\n",
      "25,900\n",
      "\n",
      "\n",
      "                Expenses +\n",
      "\n",
      "\n",
      "9\n",
      "22\n",
      "19\n",
      "34\n",
      "38\n",
      "26\n",
      "38\n",
      "48\n",
      "66\n",
      "113\n",
      "123\n",
      "134\n",
      "141\n",
      "\n",
      "            \n",
      "              Operating Profit\n",
      "            \n",
      "          \n",
      "4,633\n",
      "5,528\n",
      "6,178\n",
      "6,905\n",
      "7,468\n",
      "9,021\n",
      "9,229\n",
      "11,085\n",
      "13,355\n",
      "15,657\n",
      "20,177\n",
      "23,758\n",
      "25,760\n",
      "\n",
      "            \n",
      "              OPM %\n",
      "            \n",
      "          \n",
      "100%\n",
      "100%\n",
      "100%\n",
      "100%\n",
      "99%\n",
      "100%\n",
      "100%\n",
      "100%\n",
      "100%\n",
      "99%\n",
      "99%\n",
      "99%\n",
      "99%\n",
      "\n",
      "\n",
      "                Other Income +\n",
      "\n",
      "\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "-0\n",
      "0\n",
      "0\n",
      "2\n",
      "41\n",
      "43\n",
      "\n",
      "            \n",
      "              Interest\n",
      "            \n",
      "          \n",
      "3,620\n",
      "4,075\n",
      "4,607\n",
      "4,992\n",
      "5,519\n",
      "6,888\n",
      "6,638\n",
      "8,183\n",
      "10,163\n",
      "11,237\n",
      "14,075\n",
      "17,447\n",
      "19,721\n",
      "\n",
      "            \n",
      "              Depreciation\n",
      "            \n",
      "          \n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "14\n",
      "14\n",
      "13\n",
      "\n",
      "            \n",
      "              Profit before tax\n",
      "            \n",
      "          \n",
      "1,013\n",
      "1,454\n",
      "1,572\n",
      "1,914\n",
      "1,950\n",
      "2,133\n",
      "2,592\n",
      "2,902\n",
      "3,192\n",
      "4,416\n",
      "6,090\n",
      "6,337\n",
      "6,068\n",
      "\n",
      "            \n",
      "              Tax %\n",
      "            \n",
      "          \n",
      "53%\n",
      "64%\n",
      "55%\n",
      "60%\n",
      "56%\n",
      "56%\n",
      "21%\n",
      "22%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "\n",
      "\n",
      "\n",
      "                Net Profit +\n",
      "\n",
      "\n",
      "481\n",
      "522\n",
      "701\n",
      "758\n",
      "849\n",
      "934\n",
      "2,055\n",
      "2,255\n",
      "3,192\n",
      "4,416\n",
      "6,090\n",
      "6,337\n",
      "6,068\n",
      "\n",
      "            \n",
      "              EPS in Rs\n",
      "            \n",
      "          \n",
      "228.73\n",
      "221.76\n",
      "209.04\n",
      "211.58\n",
      "187.50\n",
      "143.08\n",
      "3.15\n",
      "2.40\n",
      "2.69\n",
      "3.38\n",
      "4.66\n",
      "4.85\n",
      "4.65\n",
      "\n",
      "            \n",
      "              Dividend Payout %\n",
      "            \n",
      "          \n",
      "21%\n",
      "21%\n",
      "6%\n",
      "20%\n",
      "40%\n",
      "40%\n",
      "18%\n",
      "18%\n",
      "0%\n",
      "31%\n",
      "30%\n",
      "31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "url = 'https://www.screener.in/company/IRFC/'  # Replace 'YOUR_URL_HERE' with the actual URL\n",
    " \n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    " \n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    " \n",
    "    # Find the section with the specified class\n",
    "    profit_loss_section = soup.find('section', {'id': 'profit-loss', 'class': 'card card-large'})\n",
    " \n",
    "    # Find the table within the section\n",
    "    table = profit_loss_section.find('table', {'class': 'data-table responsive-text-nowrap'})\n",
    " \n",
    "    # Extract data from the table\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                print(cell.text)  # Print or store the table data as needed\n",
    " \n",
    "# Handle errors or perform other tasks based on the response status code\n",
    "else:\n",
    "    print('Failed to fetch the webpage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Mar 2012 Mar 2013 Mar 2014 Mar 2015 Mar 2016 Mar 2017  \\\n",
      "0             Sales +    4,642    5,550    6,197    6,939    7,507    9,047   \n",
      "1          Expenses +        9       22       19       34       38       26   \n",
      "2    Operating Profit    4,633    5,528    6,178    6,905    7,468    9,021   \n",
      "3               OPM %     100%     100%     100%     100%      99%     100%   \n",
      "4      Other Income +        1        2        1        1        1        0   \n",
      "5            Interest    3,620    4,075    4,607    4,992    5,519    6,888   \n",
      "6        Depreciation        0        0        0        0        0        0   \n",
      "7   Profit before tax    1,013    1,454    1,572    1,914    1,950    2,133   \n",
      "8               Tax %      53%      64%      55%      60%      56%      56%   \n",
      "9        Net Profit +      481      522      701      758      849      934   \n",
      "10          EPS in Rs   228.73   221.76   209.04   211.58   187.50   143.08   \n",
      "11  Dividend Payout %      21%      21%       6%      20%      40%      40%   \n",
      "\n",
      "   Mar 2018 Mar 2019 Mar 2020 Mar 2021 Mar 2022 Mar 2023     TTM  \n",
      "0     9,267   11,134   13,421   15,771   20,299   23,892  25,900  \n",
      "1        38       48       66      113      123      134     141  \n",
      "2     9,229   11,085   13,355   15,657   20,177   23,758  25,760  \n",
      "3      100%     100%     100%      99%      99%      99%     99%  \n",
      "4         1       -0        0        0        2       41      43  \n",
      "5     6,638    8,183   10,163   11,237   14,075   17,447  19,721  \n",
      "6         0        0        0        4       14       14      13  \n",
      "7     2,592    2,902    3,192    4,416    6,090    6,337   6,068  \n",
      "8       21%      22%       0%       0%       0%       0%          \n",
      "9     2,055    2,255    3,192    4,416    6,090    6,337   6,068  \n",
      "10     3.15     2.40     2.69     3.38     4.66     4.85    4.65  \n",
      "11      18%      18%       0%      31%      30%      31%          \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.screener.in/company/IRFC/'  # Replace 'YOUR_URL_HERE' with the actual URL\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the section with the specified class\n",
    "    profit_loss_section = soup.find('section', {'id': 'profit-loss', 'class': 'card card-large'})\n",
    "\n",
    "    # Find the table within the section\n",
    "    table = profit_loss_section.find('table', {'class': 'data-table responsive-text-nowrap'})\n",
    "\n",
    "    # Extract data from the table\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        # Initialize data dictionary for DataFrame\n",
    "        data_dict = {}\n",
    "        columns = None\n",
    "\n",
    "        for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])\n",
    "            if not columns:\n",
    "                # Extract column names from the first row (header)\n",
    "                columns = [cell.text.strip() for cell in cells]\n",
    "                for col in columns:\n",
    "                    data_dict[col] = []\n",
    "\n",
    "            else:\n",
    "                # Extract data for each column\n",
    "                for i, cell in enumerate(cells):\n",
    "                    data_dict[columns[i]].append(cell.text.strip())\n",
    "\n",
    "        # Create a DataFrame from the data dictionary\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        print(df)\n",
    "\n",
    "    else:\n",
    "        print(\"Table not found on the page.\")\n",
    "\n",
    "else:\n",
    "    print('Failed to fetch the webpage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element not found on the page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ManoharMadisetty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\soupsieve\\css_parser.py:856: FutureWarning: The pseudo class ':contains' is deprecated, ':-soup-contains' should be used moving forward.\n",
      "  warnings.warn(  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.screener.in/company/IRFC/'\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Select elements with the specified class\n",
    "    manufacturing_cost_element = soup.select_one('tr:has(td.text:contains(\"Manufacturing Cost %\"))')\n",
    "\n",
    "    # Extract data from the selected element\n",
    "    if manufacturing_cost_element:\n",
    "        manufacturing_cost_data = manufacturing_cost_element.get_text(strip=True)\n",
    "        print(manufacturing_cost_data)\n",
    "    else:\n",
    "        print(\"Element not found on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
